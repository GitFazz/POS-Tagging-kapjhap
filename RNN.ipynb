{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GitFazz/POS-Tagging-kapjhap/blob/master/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjbTPoAxUhjc"
      },
      "source": [
        "IMPORT all modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3bexXfLMra4"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "import keras.utils\r\n",
        "from keras.utils.np_utils import to_categorical\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.utils import shuffle\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Embedding\r\n",
        "from keras.layers import Dense, Input\r\n",
        "from keras.layers import TimeDistributed\r\n",
        "from keras.layers import LSTM, GRU, Bidirectional, SimpleRNN, RNN\r\n",
        "from keras.models import Model\r\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtEDKQ83UoOM"
      },
      "source": [
        "Preparing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27xvCsKWvOrz"
      },
      "source": [
        "\r\n",
        "fp = open(\"base_dataset.txt\",\"r\")\r\n",
        "\r\n",
        "X = []\r\n",
        "Y = []\r\n",
        "\r\n",
        "while True:\r\n",
        "    line = fp.readline()\r\n",
        "    if not line: break\r\n",
        "\r\n",
        "    words = line.split(\" \")\r\n",
        "\r\n",
        "    X_sentence = []\r\n",
        "    Y_sentence = []\r\n",
        "\r\n",
        "    for w in words:\r\n",
        "        com = w.split(\"\\\\\")\r\n",
        "\r\n",
        "        one = com[0]\r\n",
        "        two = com[1].split(\".\",2)[0]\r\n",
        "\r\n",
        "        if len(two) < 1 : continue\r\n",
        "\r\n",
        "        # filtering dataset\r\n",
        "        if (not two.startswith(\"PU\")) and (not two.startswith(\"R\")) and (not two.startswith(\"?\")) :\r\n",
        "          \r\n",
        "          X_sentence.append(one) # add the word\r\n",
        "\r\n",
        "          if (two.startswith(\"PP\")) : \r\n",
        "            Y_sentence.append(\"PP\")\r\n",
        "          else :\r\n",
        "            Y_sentence.append(two[0]) #otherwise take only the fist letter\r\n",
        "        \r\n",
        "\r\n",
        "    X.append(X_sentence)\r\n",
        "    Y.append(Y_sentence)\r\n",
        "\r\n",
        "\r\n",
        "  \r\n",
        "\r\n",
        "fp.close()\r\n",
        "\r\n",
        "            \r\n",
        "    \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjHTtILNUsSM"
      },
      "source": [
        "Testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IG-rWyBPxqe_",
        "outputId": "193ea3f4-6aaa-4213-f069-ce26f45f682a"
      },
      "source": [
        "# let’s look at first data point\r\n",
        "# this is one data point that will be fed to the RNN\r\n",
        "print('  sample X: ', X[0], '\\n')\r\n",
        "print('sample Y: ', Y[0], '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  sample X:  ['রপ্তানি', 'দ্রব্য', 'তাজা', 'ও', 'শুকনা', 'ফল', 'আফিম', 'পশুচর্ম', 'ও', 'পশম', 'এবং', 'কার্পেট'] \n",
            "\n",
            "sample Y:  ['J', 'N', 'J', 'C', 'J', 'N', 'N', 'N', 'C', 'N', 'C', 'N'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgpPTL2HVNIP"
      },
      "source": [
        "Printing labels and size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HflzY6d2Mny2",
        "outputId": "73b2ed0b-2f0f-4dca-fb35-449d590778cd"
      },
      "source": [
        "temp = []\r\n",
        "for i in Y :\r\n",
        "  for j in i :\r\n",
        "    if j not in temp:\r\n",
        "        temp.append(j)\r\n",
        "print(temp)\r\n",
        "print('size : ',len(temp))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['J', 'N', 'C', 'V', 'P', 'D', 'PP', 'A', 'L']\n",
            "size :  9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWQWf5LVC6a0"
      },
      "source": [
        "Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "try6JC_J-BlU",
        "outputId": "65f09682-3f75-4930-9db3-4ff4a6ac005f"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\r\n",
        "\r\n",
        "# encode X\r\n",
        "word_tokenizer = Tokenizer()              # instantiate tokeniser\r\n",
        "word_tokenizer.fit_on_texts(X)            # fit tokeniser on data\r\n",
        "# use the tokeniser to encode input sequence\r\n",
        "X_encoded = word_tokenizer.texts_to_sequences(X)  \r\n",
        "# encode Y\r\n",
        "tag_tokenizer = Tokenizer()\r\n",
        "tag_tokenizer.fit_on_texts(Y)\r\n",
        "Y_encoded = tag_tokenizer.texts_to_sequences(Y)\r\n",
        "# look at first encoded data point\r\n",
        "print(\"** Raw data point **\", \"\\n\", \"-\"*100, \"\\n\")\r\n",
        "print('X: ', X[0], '\\n')\r\n",
        "print('Y: ', Y[0], '\\n')\r\n",
        "print()\r\n",
        "print(\"** Encoded data point **\", \"\\n\", \"-\"*100, \"\\n\")\r\n",
        "print('X: ', X_encoded[0], '\\n')\r\n",
        "print('Y: ', Y_encoded[0], '\\n')\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** Raw data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  ['রপ্তানি', 'দ্রব্য', 'তাজা', 'ও', 'শুকনা', 'ফল', 'আফিম', 'পশুচর্ম', 'ও', 'পশম', 'এবং', 'কার্পেট'] \n",
            "\n",
            "Y:  ['J', 'N', 'J', 'C', 'J', 'N', 'N', 'N', 'C', 'N', 'C', 'N'] \n",
            "\n",
            "\n",
            "** Encoded data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  [1215, 1216, 1643, 2, 3975, 502, 3976, 3977, 2, 3978, 5, 3979] \n",
            "\n",
            "Y:  [3, 1, 3, 5, 3, 1, 1, 1, 5, 1, 5, 1] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHXS0AfRziEd"
      },
      "source": [
        "Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwl3mcnh-_Qt",
        "outputId": "0dc7adfb-905a-4906-935d-f3b5a710a29f"
      },
      "source": [
        "# Pad each sequence to MAX_SEQ_LENGTH using KERAS’ pad_sequences() function. \r\n",
        "# Sentences longer than MAX_SEQ_LENGTH are truncated.\r\n",
        "# Sentences shorter than MAX_SEQ_LENGTH are padded with zeroes.\r\n",
        "# Truncation and padding can either be ‘pre’ or ‘post’. \r\n",
        "# For padding we are using ‘pre’ padding type, that is, add zeroes on the left side.\r\n",
        "# For truncation, we are using ‘post’, that is, truncate a sentence from right side.\r\n",
        "# sequences greater than 100 in length will be truncated\r\n",
        "\r\n",
        "from keras.preprocessing.sequence import pad_sequences \r\n",
        "\r\n",
        "MAX_SEQ_LENGTH = 90\r\n",
        "X_padded = pad_sequences(X_encoded, maxlen=MAX_SEQ_LENGTH, padding='pre', truncating='post')\r\n",
        "Y_padded = pad_sequences(Y_encoded, maxlen=MAX_SEQ_LENGTH, padding='pre', truncating='post')\r\n",
        "# print the first sequence\r\n",
        "print(X_padded[0], \"\\n\"*3)\r\n",
        "print(Y_padded[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0 1215 1216 1643    2 3975  502\n",
            " 3976 3977    2 3978    5 3979] \n",
            "\n",
            "\n",
            "\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 3 1 3 5 3 1 1 1 5 1 5 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LzmDTeTDHIH"
      },
      "source": [
        "Longest sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfIiNWRKDIiF",
        "outputId": "e15ee96f-9686-458c-debe-38c71201577d"
      },
      "source": [
        "# check length of longest sentence\r\n",
        "lengths = [len(seq) for seq in X_encoded]\r\n",
        "print(\"Length of longest sentence: {}\".format(max(lengths)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of longest sentence: 96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtSS_xweDaNe"
      },
      "source": [
        "Update X and Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGqrBENoDbkQ"
      },
      "source": [
        "X, Y = X_padded, Y_padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhK92fYXwrwF"
      },
      "source": [
        "Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAJum3XoB7r5"
      },
      "source": [
        "\r\n",
        "# assign word vectors from word2vec model\r\n",
        "# each word in word2vec model is represented using a 300 dimensional vector\r\n",
        "EMBEDDING_SIZE  = 300  \r\n",
        "VOCABULARY_SIZE = len(word_tokenizer.word_index) + 1\r\n",
        "NUM_CLASSES = 9\r\n",
        "# create an empty embedding matix\r\n",
        "embedding_weights = np.zeros((VOCABULARY_SIZE, EMBEDDING_SIZE))\r\n",
        "# create a word to index dictionary mapping\r\n",
        "word2id = word_tokenizer.word_index\r\n",
        "# copy vectors from word2vec model to the words present in corpus\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoUuY3Y9Kq2O"
      },
      "source": [
        "Use one-hot encoding for output sequences (Y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5_jOiJJDsnG",
        "outputId": "72c596e2-411f-485a-bb00-86e28fa5b3fd"
      },
      "source": [
        "# use Keras' to_categorical function to one-hot encode Y\r\n",
        "Y = to_categorical(Y)\r\n",
        "print(Y.shape[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zxLF3Jqz9Et"
      },
      "source": [
        "Splitting test and train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAzIGzHYz-2m"
      },
      "source": [
        "TEST_SIZE = 0.33\r\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=TEST_SIZE, random_state=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka33lI7U6odl"
      },
      "source": [
        "Vanilla RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xYcwoWN8e_6"
      },
      "source": [
        "Let’s start with the first experiment: a vanilla RNN with arbitrarily initialized, untrainable embedding. For this RNN we won’t use the pre-trained word embeddings. We’ll use randomly initialized embeddings. Moreover, we won’t update the embeddings weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZQxa8ka8f27",
        "outputId": "17926b78-fbcd-409a-ff0d-4cbf8af0d6f6"
      },
      "source": [
        "# create architecture\r\n",
        "rnn_model = keras.Sequential()\r\n",
        "# create embedding layer — usually the first layer in text problems\r\n",
        "# vocabulary size — number of unique words in data\r\n",
        "rnn_model.add(layers.Embedding(input_dim = VOCABULARY_SIZE, \r\n",
        "# length of vector with which each word is represented\r\n",
        " output_dim = EMBEDDING_SIZE, \r\n",
        "# length of input sequence\r\n",
        " input_length = MAX_SEQ_LENGTH, \r\n",
        "# False — don’t update the embeddings\r\n",
        " trainable = True \r\n",
        "))\r\n",
        "# add an RNN layer which contains 64 RNN cells\r\n",
        "# True — return whole sequence; False — return single output of the end of the sequence\r\n",
        "rnn_model.add(layers.SimpleRNN(64, \r\n",
        " return_sequences=True\r\n",
        "))\r\n",
        "# add time distributed (output at each sequence) layer\r\n",
        "\r\n",
        "rnn_model.add(layers.TimeDistributed(layers.Dense(NUM_CLASSES+1, activation='softmax')))\r\n",
        "#compile model\r\n",
        "rnn_model.compile(loss      =  'categorical_crossentropy',\r\n",
        "                  optimizer =  'adam',\r\n",
        "                  metrics   =  ['acc']) \r\n",
        "# check summary of the model\r\n",
        "rnn_model.summary()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 90, 300)           3685500   \n",
            "_________________________________________________________________\n",
            "simple_rnn (SimpleRNN)       (None, 90, 64)            23360     \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 90, 10)            650       \n",
            "=================================================================\n",
            "Total params: 3,709,510\n",
            "Trainable params: 3,709,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIUd6xvN_mCk"
      },
      "source": [
        "Vanila RNN fit model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXRwbUMLqRHW",
        "outputId": "2b6cfcf3-7984-4412-ca0d-19e7293384c5"
      },
      "source": [
        "rnn_training = rnn_model.fit(X_train,Y_train,batch_size=128,epochs=10, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 4s 180ms/step - loss: 1.6663 - acc: 0.6734 - val_loss: 0.5677 - val_acc: 0.8695\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 2s 142ms/step - loss: 0.5402 - acc: 0.8697 - val_loss: 0.4069 - val_acc: 0.8893\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 2s 145ms/step - loss: 0.3761 - acc: 0.9036 - val_loss: 0.3306 - val_acc: 0.8900\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.2959 - acc: 0.9089 - val_loss: 0.2730 - val_acc: 0.9203\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.2383 - acc: 0.9361 - val_loss: 0.2313 - val_acc: 0.9318\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.1952 - acc: 0.9436 - val_loss: 0.2007 - val_acc: 0.9392\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.1646 - acc: 0.9509 - val_loss: 0.1779 - val_acc: 0.9481\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 0.1376 - acc: 0.9610 - val_loss: 0.1588 - val_acc: 0.9564\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.1155 - acc: 0.9701 - val_loss: 0.1420 - val_acc: 0.9624\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 0.0976 - acc: 0.9777 - val_loss: 0.1285 - val_acc: 0.9673\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjhmuwIgGPRb"
      },
      "source": [
        "Vanila RNN Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8PoGmJ9GQsx",
        "outputId": "55d8bda3-eb1d-4972-9f48-7d43a0d98f7d"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.metrics import precision_score\r\n",
        "from sklearn.metrics import recall_score\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from sklearn.metrics import cohen_kappa_score\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "pred = rnn_model.predict(X_test)\r\n",
        "predict = np.array([np.argmax(y, axis=1) for y in pred])\r\n",
        "actual = np.array([np.argmax(y, axis=1) for y in Y_test])\r\n",
        "\r\n",
        "predict = predict.flatten()\r\n",
        "actual = actual.flatten()\r\n",
        "\r\n",
        "true_pos = 0\r\n",
        "false_pos = 0\r\n",
        "true_neg = 0\r\n",
        "false_neg = 0\r\n",
        "\r\n",
        "for j in range(1, NUM_CLASSES+1):\r\n",
        "  true_pos += sum(1 for i in range(len(predict)) if (predict[i]==j) & (actual[i]==j))\r\n",
        "  false_pos += sum(1 for i in range(len(predict)) if (predict[i]==j) & (actual[i]!=j))\r\n",
        "  true_neg += sum(1 for i in range(len(predict)) if (predict[i]!=j) & (actual[i]!=j))\r\n",
        "  false_neg += sum(1 for i in range(len(predict)) if (predict[i]!=j) & (actual[i]==j))\r\n",
        "\r\n",
        "accuracy = (true_pos+true_neg)/(true_neg+true_pos+false_neg+false_pos)\r\n",
        "precision = true_pos/(true_pos+false_pos)\r\n",
        "recall = true_pos/(true_pos+false_neg)\r\n",
        "f_score = 2.0*precision*recall/(precision+recall)\r\n",
        "print(\"Accuracy: %.3f\" % (accuracy))\r\n",
        "print(\"F1 score: %.3f\" % (f_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.993\n",
            "F1 score: 0.758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n80Txpzro8GY"
      },
      "source": [
        "LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJjVnQw1o9RQ",
        "outputId": "1e24f0be-3c80-4cc0-ee64-9da81c40f8f4"
      },
      "source": [
        "# create architecture\r\n",
        "lstm_model = Sequential()\r\n",
        "# vocabulary size — number of unique words in data\r\n",
        "# length of vector with which each word is represented\r\n",
        "lstm_model.add(Embedding(input_dim = VOCABULARY_SIZE,\r\n",
        "output_dim = EMBEDDING_SIZE,\r\n",
        "# length of input sequence\r\n",
        "input_length = MAX_SEQ_LENGTH,\r\n",
        "# True — update embeddings_weight matrix\r\n",
        "trainable = True\r\n",
        "))\r\n",
        "# add an LSTM layer which contains 64 LSTM cells\r\n",
        "# True — return whole sequence; False — return single output of the end of the sequence\r\n",
        "lstm_model.add(LSTM(64, return_sequences=True))\r\n",
        "lstm_model.add(TimeDistributed(Dense(NUM_CLASSES+1,\r\n",
        "activation='softmax')))\r\n",
        "#compile model\r\n",
        "lstm_model.compile(loss = 'categorical_crossentropy',\r\n",
        "                          optimizer = 'adam',\r\n",
        "                          metrics = ['acc'])\r\n",
        "# check summary of the model\r\n",
        "lstm_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 80, 300)           3685500   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 80, 64)            93440     \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 80, 10)            650       \n",
            "=================================================================\n",
            "Total params: 3,779,590\n",
            "Trainable params: 3,779,590\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MOn31xlp4DP"
      },
      "source": [
        "LSTM train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkE05l-wp60i",
        "outputId": "26d55835-7a9d-4c66-9c5d-ab6e98b26674"
      },
      "source": [
        "lstm_training = lstm_model.fit(X_train,Y_train,batch_size=128,epochs=10, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 80) for input KerasTensor(type_spec=TensorSpec(shape=(None, 80), dtype=tf.float32, name='embedding_4_input'), name='embedding_4_input', description=\"created by layer 'embedding_4_input'\"), but it was called on an input with incompatible shape (None, 90).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 80) for input KerasTensor(type_spec=TensorSpec(shape=(None, 80), dtype=tf.float32, name='embedding_4_input'), name='embedding_4_input', description=\"created by layer 'embedding_4_input'\"), but it was called on an input with incompatible shape (None, 90).\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8692 - acc: 0.6821WARNING:tensorflow:Model was constructed with shape (None, 80) for input KerasTensor(type_spec=TensorSpec(shape=(None, 80), dtype=tf.float32, name='embedding_4_input'), name='embedding_4_input', description=\"created by layer 'embedding_4_input'\"), but it was called on an input with incompatible shape (None, 90).\n",
            "16/16 [==============================] - 7s 349ms/step - loss: 1.8420 - acc: 0.6898 - val_loss: 0.6270 - val_acc: 0.8695\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 0.5871 - acc: 0.8694 - val_loss: 0.4155 - val_acc: 0.8794\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 0.3898 - acc: 0.8924 - val_loss: 0.3314 - val_acc: 0.9043\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 0.3120 - acc: 0.9111 - val_loss: 0.2807 - val_acc: 0.9200\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 0.2668 - acc: 0.9229 - val_loss: 0.2524 - val_acc: 0.9241\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 0.2335 - acc: 0.9286 - val_loss: 0.2348 - val_acc: 0.9254\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.2221 - acc: 0.9273 - val_loss: 0.2213 - val_acc: 0.9269\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 0.2080 - acc: 0.9282 - val_loss: 0.2091 - val_acc: 0.9276\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 0.1948 - acc: 0.9324 - val_loss: 0.1962 - val_acc: 0.9314\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 0.1779 - acc: 0.9383 - val_loss: 0.1816 - val_acc: 0.9361\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB6ZEYl2uhle"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFd7KIMKqBI2"
      },
      "source": [
        "LSTM Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fx2AMS8RqCpo",
        "outputId": "96dfcecf-06e2-49b2-91a2-a06691118508"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.metrics import precision_score\r\n",
        "from sklearn.metrics import recall_score\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from sklearn.metrics import cohen_kappa_score\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "pred = lstm_model.predict(X_test)\r\n",
        "predict = np.array([np.argmax(y, axis=1) for y in pred])\r\n",
        "actual = np.array([np.argmax(y, axis=1) for y in Y_test])\r\n",
        "\r\n",
        "predict = predict.flatten()\r\n",
        "actual = actual.flatten()\r\n",
        "\r\n",
        "true_pos = 0\r\n",
        "false_pos = 0\r\n",
        "true_neg = 0\r\n",
        "false_neg = 0\r\n",
        "\r\n",
        "for j in range(1, NUM_CLASSES+1):\r\n",
        "  true_pos += sum(1 for i in range(len(predict)) if (predict[i]==j) & (actual[i]==j))\r\n",
        "  false_pos += sum(1 for i in range(len(predict)) if (predict[i]==j) & (actual[i]!=j))\r\n",
        "  true_neg += sum(1 for i in range(len(predict)) if (predict[i]!=j) & (actual[i]!=j))\r\n",
        "  false_neg += sum(1 for i in range(len(predict)) if (predict[i]!=j) & (actual[i]==j))\r\n",
        "\r\n",
        "accuracy = (true_pos+true_neg)/(true_neg+true_pos+false_neg+false_pos)\r\n",
        "precision = true_pos/(true_pos+false_pos)\r\n",
        "recall = true_pos/(true_pos+false_neg)\r\n",
        "f_score = 2.0*precision*recall/(precision+recall)\r\n",
        "print(\"Accuracy: %.3f\" % (accuracy))\r\n",
        "print(\"F1 score: %.3f\" % (f_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 80) for input KerasTensor(type_spec=TensorSpec(shape=(None, 80), dtype=tf.float32, name='embedding_4_input'), name='embedding_4_input', description=\"created by layer 'embedding_4_input'\"), but it was called on an input with incompatible shape (None, 90).\n",
            "Accuracy: 0.986\n",
            "F1 score: 0.521\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K5DRzRTsKwA"
      },
      "source": [
        "GRU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "st9XjnMnshcV",
        "outputId": "23d2996f-9cc6-4f21-8c60-e4f8d00317d7"
      },
      "source": [
        "# create architecture\r\n",
        "gru_model = Sequential()\r\n",
        "# vocabulary size — number of unique words in data\r\n",
        "# length of vector with which each word is represented\r\n",
        "gru_model.add(Embedding(input_dim = VOCABULARY_SIZE,\r\n",
        "output_dim = EMBEDDING_SIZE,\r\n",
        "# length of input sequence\r\n",
        "input_length = MAX_SEQ_LENGTH,\r\n",
        "\r\n",
        "# True — update embeddings_weight matrix\r\n",
        "trainable = True\r\n",
        "))\r\n",
        "# add an LSTM layer which contains 64 LSTM cells\r\n",
        "# True — return whole sequence; False — return single output of the end of the sequence\r\n",
        "\r\n",
        "gru_model.add(GRU(64, return_sequences=True))\r\n",
        "gru_model.add(TimeDistributed(Dense(NUM_CLASSES+1,\r\n",
        "activation='softmax')))\r\n",
        "#compile model\r\n",
        "gru_model.compile(loss = 'categorical_crossentropy', \r\n",
        "                  optimizer = 'adam',\r\n",
        "                  metrics = ['acc'])\r\n",
        "\r\n",
        "# check summary of the model\r\n",
        "gru_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 90, 300)           3685500   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 90, 64)            70272     \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 90, 10)            650       \n",
            "=================================================================\n",
            "Total params: 3,756,422\n",
            "Trainable params: 3,756,422\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f_hoDFFtIq0"
      },
      "source": [
        "GRU Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-U00enbtLML",
        "outputId": "4f7b2194-c2d6-41f7-b71f-b5d59e42c300"
      },
      "source": [
        "gru_training = gru_model.fit(X_train,Y_train,batch_size=128,epochs=10, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 6s 302ms/step - loss: 1.9096 - acc: 0.7102 - val_loss: 0.5612 - val_acc: 0.8696\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 4s 272ms/step - loss: 0.4575 - acc: 0.8699 - val_loss: 0.3555 - val_acc: 0.8898\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 4s 275ms/step - loss: 0.3173 - acc: 0.9079 - val_loss: 0.2901 - val_acc: 0.9193\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 4s 272ms/step - loss: 0.2749 - acc: 0.9320 - val_loss: 0.2604 - val_acc: 0.9300\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 4s 271ms/step - loss: 0.2398 - acc: 0.9387 - val_loss: 0.2319 - val_acc: 0.9332\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 4s 273ms/step - loss: 0.2079 - acc: 0.9370 - val_loss: 0.2037 - val_acc: 0.9361\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 4s 277ms/step - loss: 0.1715 - acc: 0.9436 - val_loss: 0.1761 - val_acc: 0.9469\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 4s 277ms/step - loss: 0.1450 - acc: 0.9556 - val_loss: 0.1505 - val_acc: 0.9602\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 4s 274ms/step - loss: 0.1148 - acc: 0.9705 - val_loss: 0.1290 - val_acc: 0.9671\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 4s 276ms/step - loss: 0.0899 - acc: 0.9787 - val_loss: 0.1129 - val_acc: 0.9711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTa_URcvtm0j"
      },
      "source": [
        "GRU Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3sh_Vq7todZ",
        "outputId": "65cb4de4-e3d6-476c-c7a8-9b35c8a01c68"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.metrics import precision_score\r\n",
        "from sklearn.metrics import recall_score\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from sklearn.metrics import cohen_kappa_score\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "pred = gru_model.predict(X_test)\r\n",
        "predict = np.array([np.argmax(y, axis=1) for y in pred])\r\n",
        "actual = np.array([np.argmax(y, axis=1) for y in Y_test])\r\n",
        "\r\n",
        "predict = predict.flatten()\r\n",
        "actual = actual.flatten()\r\n",
        "\r\n",
        "true_pos = 0\r\n",
        "false_pos = 0\r\n",
        "true_neg = 0\r\n",
        "false_neg = 0\r\n",
        "\r\n",
        "for j in range(1, NUM_CLASSES+1):\r\n",
        "  true_pos += sum(1 for i in range(len(predict)) if (predict[i]==j) & (actual[i]==j))\r\n",
        "  false_pos += sum(1 for i in range(len(predict)) if (predict[i]==j) & (actual[i]!=j))\r\n",
        "  true_neg += sum(1 for i in range(len(predict)) if (predict[i]!=j) & (actual[i]!=j))\r\n",
        "  false_neg += sum(1 for i in range(len(predict)) if (predict[i]!=j) & (actual[i]==j))\r\n",
        "\r\n",
        "accuracy = (true_pos+true_neg)/(true_neg+true_pos+false_neg+false_pos)\r\n",
        "precision = true_pos/(true_pos+false_pos)\r\n",
        "recall = true_pos/(true_pos+false_neg)\r\n",
        "f_score = 2.0*precision*recall/(precision+recall)\r\n",
        "print(\"Accuracy: %.3f\" % (accuracy))\r\n",
        "print(\"F1 score: %.3f\" % (f_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.994\n",
            "F1 score: 0.797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d_RNFUouKU2"
      },
      "source": [
        "Bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxEgKLoxuPL1",
        "outputId": "d0fcf140-be29-4e00-ade7-6eae2ccbf00e"
      },
      "source": [
        "# create architecture\r\n",
        "bidirect_model = Sequential()\r\n",
        "bidirect_model.add(Embedding(input_dim = VOCABULARY_SIZE,\r\n",
        "output_dim = EMBEDDING_SIZE,\r\n",
        "input_length = MAX_SEQ_LENGTH,\r\n",
        "trainable = True\r\n",
        "))\r\n",
        "bidirect_model.add(Bidirectional(LSTM(64, return_sequences=True)))\r\n",
        "bidirect_model.add(TimeDistributed(Dense(NUM_CLASSES+1,\r\n",
        "activation='softmax')))\r\n",
        "#compile model\r\n",
        "bidirect_model.compile(loss='categorical_crossentropy',\r\n",
        "                       optimizer='adam',\r\n",
        "                       metrics=['acc'])\r\n",
        "# check summary of model\r\n",
        "bidirect_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 90, 300)           3685500   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 90, 128)           186880    \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 90, 10)            1290      \n",
            "=================================================================\n",
            "Total params: 3,873,670\n",
            "Trainable params: 3,873,670\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaKugHdpujJ8"
      },
      "source": [
        "Bidirectional Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iCw7mFAumqP",
        "outputId": "e078b1b7-c980-472c-f720-7f55f6e37e11"
      },
      "source": [
        "bidirect_training = bidirect_model.fit(X_train,Y_train,batch_size=128,epochs=20, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 14s 679ms/step - loss: 1.6400 - acc: 0.6982 - val_loss: 0.4153 - val_acc: 0.8695\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 10s 615ms/step - loss: 0.3606 - acc: 0.8772 - val_loss: 0.2793 - val_acc: 0.9206\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 10s 616ms/step - loss: 0.2786 - acc: 0.9228 - val_loss: 0.2512 - val_acc: 0.9282\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 10s 619ms/step - loss: 0.2487 - acc: 0.9276 - val_loss: 0.2350 - val_acc: 0.9296\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 10s 616ms/step - loss: 0.2336 - acc: 0.9292 - val_loss: 0.2239 - val_acc: 0.9303\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 10s 618ms/step - loss: 0.2238 - acc: 0.9290 - val_loss: 0.2146 - val_acc: 0.9301\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 10s 620ms/step - loss: 0.2086 - acc: 0.9309 - val_loss: 0.2052 - val_acc: 0.9307\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 10s 617ms/step - loss: 0.1960 - acc: 0.9316 - val_loss: 0.1938 - val_acc: 0.9331\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 10s 620ms/step - loss: 0.1753 - acc: 0.9377 - val_loss: 0.1792 - val_acc: 0.9405\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 10s 615ms/step - loss: 0.1594 - acc: 0.9453 - val_loss: 0.1606 - val_acc: 0.9526\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 10s 613ms/step - loss: 0.1368 - acc: 0.9582 - val_loss: 0.1398 - val_acc: 0.9652\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 10s 616ms/step - loss: 0.1084 - acc: 0.9725 - val_loss: 0.1209 - val_acc: 0.9717\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 10s 617ms/step - loss: 0.0854 - acc: 0.9814 - val_loss: 0.1058 - val_acc: 0.9741\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 10s 616ms/step - loss: 0.0697 - acc: 0.9851 - val_loss: 0.0938 - val_acc: 0.9762\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 10s 612ms/step - loss: 0.0535 - acc: 0.9883 - val_loss: 0.0865 - val_acc: 0.9778\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 10s 615ms/step - loss: 0.0441 - acc: 0.9909 - val_loss: 0.0814 - val_acc: 0.9790\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 10s 612ms/step - loss: 0.0365 - acc: 0.9924 - val_loss: 0.0776 - val_acc: 0.9794\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 10s 622ms/step - loss: 0.0303 - acc: 0.9936 - val_loss: 0.0762 - val_acc: 0.9795\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 10s 622ms/step - loss: 0.0267 - acc: 0.9942 - val_loss: 0.0731 - val_acc: 0.9803\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 10s 612ms/step - loss: 0.0231 - acc: 0.9947 - val_loss: 0.0727 - val_acc: 0.9803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF3K6V6vvhgV"
      },
      "source": [
        "Bidirectional testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-OeeXjrvmfx",
        "outputId": "41c49d17-091f-42f2-c517-ea00b2970f5d"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.metrics import precision_score\r\n",
        "from sklearn.metrics import recall_score\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from sklearn.metrics import cohen_kappa_score\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "pred = bidirect_model.predict(X_test)\r\n",
        "predict = np.array([np.argmax(y, axis=1) for y in pred])\r\n",
        "actual = np.array([np.argmax(y, axis=1) for y in Y_test])\r\n",
        "\r\n",
        "predict = predict.flatten()\r\n",
        "actual = actual.flatten()\r\n",
        "\r\n",
        "true_pos = 0\r\n",
        "false_pos = 0\r\n",
        "true_neg = 0\r\n",
        "false_neg = 0\r\n",
        "\r\n",
        "for j in range(1, NUM_CLASSES+1):\r\n",
        "  true_pos += sum(1 for i in range(len(predict)) if (predict[i]==j) & (actual[i]==j))\r\n",
        "  false_pos += sum(1 for i in range(len(predict)) if (predict[i]==j) & (actual[i]!=j))\r\n",
        "  true_neg += sum(1 for i in range(len(predict)) if (predict[i]!=j) & (actual[i]!=j))\r\n",
        "  false_neg += sum(1 for i in range(len(predict)) if (predict[i]!=j) & (actual[i]==j))\r\n",
        "\r\n",
        "accuracy = (true_pos+true_neg)/(true_neg+true_pos+false_neg+false_pos)\r\n",
        "precision = true_pos/(true_pos+false_pos)\r\n",
        "recall = true_pos/(true_pos+false_neg)\r\n",
        "f_score = 2.0*precision*recall/(precision+recall)\r\n",
        "print(\"Accuracy: %.3f\" % (accuracy))\r\n",
        "print(\"F1 score: %.3f\" % (f_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.996\n",
            "F1 score: 0.859\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}